{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA316_Amazon-rs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj-ONW3uxSIw",
        "colab_type": "text"
      },
      "source": [
        "#@authors:\n",
        "Fritz poka Toukam \n",
        "\n",
        "\n",
        "ndjekoua sandjo jean thibaut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4IfbIJAwjF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import copy, deepcopy\n",
        "import random\n",
        "from scipy.stats import norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uFxAWNswz2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_argmax(rng, list_):\n",
        "    \"\"\" similar to np.argmax but return a random element among max\n",
        "        when multiple max exists.\"\"\"\n",
        "    return rng.choice(np.argwhere(list_ == list_.max()).flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slHV4J_Bw5Dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(precision=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JEkia46w9Dk",
        "colab_type": "text"
      },
      "source": [
        "#Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krdCXQJHxFYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Amazon_environment:\n",
        "    \"\"\" A rating environment with explicit feedback.\n",
        "        User and items are represented by points in R^k\n",
        "        items_features  is the number of features that carachterizes each item\n",
        "        User interest for a given item is modeled by a parametric function\n",
        "        R_{u,i} = f(u,i) = f(W_u, W_i)\n",
        "        Example of function include dot product (cosine similarity)\n",
        "        R_{u,i} = \\sum_k w_{u,k} . w_{i,k}\n",
        "        action: Recommend one item for a given user among those he has never bought before\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nb_users=30, nb_items=10,items_featues=2, \n",
        "                 internal_embedding_size=3,nb_actions = 2,\n",
        "                 displayed_users_embedding_size=2,\n",
        "                 displayed_items_embedding_size=2,\n",
        "                 noise_size=3,\n",
        "                 seed=None):\n",
        "        self.nb_users = nb_users\n",
        "        self.nb_actions = nb_actions\n",
        "        self.nb_items = nb_items\n",
        "        self.items_featues = items_featues\n",
        "        self.internal_embedding_size = internal_embedding_size\n",
        "        self.displayed_users_embedding_size = displayed_users_embedding_size\n",
        "        self.displayed_items_embedding_size = displayed_items_embedding_size\n",
        "        self.noise_size = noise_size\n",
        "        self._rng = np.random.RandomState(seed)\n",
        "        \n",
        "        self.action_size = self.nb_items\n",
        "        self.sampling_limit = nb_users * nb_items\n",
        "        self.user_mean = np.ones(self.internal_embedding_size)\n",
        "        self.user_var = np.ones(self.internal_embedding_size)\n",
        "        self.item_mean = np.ones(self.internal_embedding_size)\n",
        "        self.item_var = np.ones(self.internal_embedding_size)\n",
        "        self.users_embedding = None\n",
        "        self.items_embedding = None\n",
        "        self.user_item_history = None\n",
        "        self.z_cut_points = None\n",
        "        self.done = False\n",
        "\n",
        "    def step(self, actions):\n",
        "        # check if behind done\n",
        "        if self.done: #self.user_item_history.sum() >= self.sampling_limit:\n",
        "            print(\"You are calling step after it return done=True.\\n\"\n",
        "                  \"You should reset the environment.\")\n",
        "\n",
        "        assert len(actions) == self.nb_actions\n",
        "        self.actions = actions\n",
        "        \n",
        "        # compute potential rewards\n",
        "        potential_rewards =np.array([self.users_embedding[self.current_user].dot(self.items_embedding[i])*self.items_features_matrix[i][0]\n",
        "                             for i in np.argwhere(self.user_item_history[self.current_user, :] == 0).flatten()])\n",
        "        \n",
        "        optimal_indexes = np.argsort(potential_rewards)[-1:0:-1][:self.nb_actions]\n",
        "        optimal_return = np.sum(potential_rewards[optimal_indexes]) \n",
        "\n",
        "        # map action to item\n",
        "        #this step is crucial because, since the user only sees the available items, it's action index is  mapped to that list, so in order to get the\n",
        "        #corresponding index in the history matrix, we need to use the trick below.\n",
        "        bought_items =[a for a in actions if a in optimal_indexes]\n",
        "        if bought_items != []:#do this only if there is one item which have been bougth by the user.otherwise, do nothing\n",
        "          bought_items = np.argwhere(self.user_item_history[self.current_user, :] == 0)[bought_items][:,0]\n",
        "          # mark item as rated\n",
        "          self.user_item_history[self.current_user, bought_items] = 1\n",
        "          self.items_features_matrix[bought_items,1]-=1\n",
        "\n",
        "        # compute reward R_t\n",
        "        recommended_items = np.argwhere(self.user_item_history[self.current_user, :] == 0)[actions][:,0]\n",
        "        self.current_rating = [self._get_user_item_reward(self.current_user, a) for a in recommended_items]\n",
        "        self.reward = np.sum(self.current_rating)\n",
        "        \n",
        "        # check if done\n",
        "        if self.user_item_history.sum() == self.sampling_limit:\n",
        "            self.done = True\n",
        "\n",
        "        # compute next state S_{t+1}\n",
        "        self._next_state()\n",
        "\n",
        "        # update action space t+1\n",
        "        self.action_size = len(self.available_items)\n",
        "\n",
        "        return self.reward, self.state, self.done, optimal_return\n",
        "\n",
        "    def init_items_features_matrix(self,nb_items,nb_features):\n",
        "        price = np.random.randint(low=100,high=1000, size=nb_items)\n",
        "        disponibility = np.array([10]*nb_items)\n",
        "        matrix = np.array([price,disponibility]).T\n",
        "        return matrix\n",
        "\n",
        "        items_features_matrix = np\n",
        "    def reset(self, seed=None):\n",
        "        self._rng = np.random.RandomState(seed)\n",
        "        self.action_size = self.nb_items\n",
        "        \n",
        "        # create users and items embedding matrix\n",
        "        self.users_embedding = self._rng.normal(loc=self.user_mean,\n",
        "                                                scale=self.user_var,\n",
        "                                                size=(self.nb_users, self.internal_embedding_size))\n",
        "        self.items_embedding = self._rng.normal(loc=self.item_mean,\n",
        "                                                scale=self.item_var,\n",
        "                                                size=(self.nb_items, self.internal_embedding_size))\n",
        "\n",
        "        #create the matrix of items_features\n",
        "        self.items_features_matrix = self.init_items_features_matrix(self.nb_items,self.items_featues)\n",
        "\n",
        "        self.user_item_history = np.zeros((self.nb_users, self.nb_items))\n",
        "        self.done = False\n",
        "\n",
        "        self._next_state()\n",
        "        return self.state\n",
        "\n",
        "    def _get_user_item_reward(self, user, item):\n",
        "        mean = self.users_embedding[user].dot(self.items_embedding[item])*self.items_features_matrix[item][0] #array of expected reward where each value correspond to one action\n",
        "        var = 1\n",
        "        reward = self._rng.normal(loc=mean,scale=var,size= 1)\n",
        "        return reward\n",
        "\n",
        "    \n",
        "\n",
        "    def _get_new_user(self):\n",
        "        for i in range(10):\n",
        "            user = self._rng.randint(0, self.nb_users)\n",
        "            # check it remain at least one item\n",
        "            if np.sum(self.user_item_history[user, :]) < self.nb_items:\n",
        "                return user\n",
        "        return self._rng.choice(np.argwhere(self.user_item_history == 0))[0]\n",
        "\n",
        "    def _next_state(self):\n",
        "        # Pick a user\n",
        "        if self.user_item_history.sum() < self.sampling_limit:\n",
        "            self.current_user = self._get_new_user()\n",
        "        else:\n",
        "            self.current_user = None\n",
        "\n",
        "        # List available items\n",
        "        #this method will return an array, where each eleemnt is also an array\n",
        "        self.available_items = np.argwhere(self.user_item_history[self.current_user, :] == 0)\n",
        "\n",
        "        self.state = list()\n",
        "        for i in self.available_items:\n",
        "            item = i[0]\n",
        "            # Compute variables\n",
        "            if self.items_features_matrix[item,1] > 0: #return only items tht are sill available.\n",
        "             self.state.append([self.current_user, item])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWGah95JsHz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = [122,1,2,13,234,55,3]\n",
        "a=np.argsort(a)[-1:0:-1][0:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vGxwngRrQ5v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "472dad99-bd5a-4407-cde3-78ec3c95bdcf"
      },
      "source": [
        "env = Amazon_environment()\n",
        "env.reset(seed=2020)\n",
        "reward, next_state, done, optimal_return = env.step(np.array([0,1]))\n",
        "print('reward: ', reward,optimal_return)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reward:  2136.0745470801758 5203.690554546546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL4p5vnfx3dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Random:\n",
        "    \"\"\" Random agent. \"\"\"\n",
        "    def __init__(self, nb_arms, seed=None):\n",
        "        self._nb_arms = nb_arms\n",
        "        self._rng = np.random.RandomState(seed)\n",
        "        \n",
        "    def act(self, context):\n",
        "        action = self._rng.randint(len(context)) # note that action size is changing\n",
        "        return action\n",
        "        \n",
        "    def update(self, context, action, reward):\n",
        "        pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}